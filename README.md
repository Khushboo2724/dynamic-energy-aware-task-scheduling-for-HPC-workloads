# **Energy-Aware Meta-Scheduler for HPC on Kubernetes**

## **Overview**

This project focuses on optimizing **high-performance computing (HPC) workloads** using an **energy-aware meta-scheduler** in a **Kubernetes + Docker** environment. The scheduler intelligently assigns tasksâ€”**data processing, machine learning (ML), and simulation**â€”based on real-time **energy and resource metrics** collected using **Prometheus**. The system enhances energy efficiency while maintaining performance across **microservices-based HPC environments**.

---

## **Project Structure**

```
ğŸ“‚ Energy-Aware-HPC-Scheduler/
â”‚â”€â”€ ğŸ“‚ container/                     # Contains all containerized tasks
â”‚   â”œâ”€â”€ ğŸ“‚ data-processing-task/      # Data processing workload container
â”‚   â”œâ”€â”€ ğŸ“‚ ml-task/                   # Machine learning workload container
â”‚   â”œâ”€â”€ ğŸ“‚ simulation-task/           # Simulation workload container
â”‚â”€â”€ ğŸ“‚ meta-scheduler/                # Intelligent energy-aware scheduler
â”‚   â”œâ”€â”€ scheduler.py                  # Main scheduling logic
â”‚   â”œâ”€â”€ node_metrics_collector.py     # Fetches real-time node metrics
â”‚   â”œâ”€â”€ energy_model.py               # Energy consumption prediction
â”‚â”€â”€ ğŸ“‚ k8s-deployments/                # Kubernetes YAML manifests
â”‚   â”œâ”€â”€ data-processing.yaml          # K8s deployment for data processing
â”‚   â”œâ”€â”€ ml-task.yaml                  # K8s deployment for ML task
â”‚   â”œâ”€â”€ simulation-task.yaml          # K8s deployment for simulation
â”‚   â”œâ”€â”€ scheduler-deployment.yaml     # Meta-scheduler Kubernetes deployment
â”‚â”€â”€ ğŸ“‚ monitoring/                     # System monitoring setup
â”‚   â”œâ”€â”€ prometheus-config.yaml        # Prometheus configuration
â”‚â”€â”€ ğŸ“‚ output/                         # Stores logs and results
â”‚â”€â”€ requirements.txt                    # Python dependencies
â”‚â”€â”€ README.md                           # Project documentation
â”‚â”€â”€ setup.sh                            # Script to deploy all components
```

---

## **Key Features**

### **1. Containerized Workloads**

- **Data Processing Task**: Handles large-scale data transformations using Spark.
- **Machine Learning Task**: Trains models efficiently using TensorFlow/PyTorch.
- **Simulation Task**: Runs physics-based or computational simulations.

### **2. Meta-Scheduler**

- Uses **task-based scheduling** instead of simple round-robin or FIFO methods.
- Collects **real-time node energy consumption and resource metrics**.
- Adapts workload placement to **minimize energy waste** while optimizing performance.

### **3. Kubernetes Integration**

- Deploys all tasks and the scheduler as **Kubernetes Pods**.
- Uses **Prometheus** to collect system-wide metrics.
- Supports **scalability and efficient resource allocation** in cloud/HPC clusters.

---

## **Installation & Execution**

### **Step 1: Build and Run Docker Containers**

```sh
# Build container images
docker build -t hpc-data-processing:latest container/data-processing-task/
docker build -t hpc-ml-training:latest container/ml-task/
docker build -t hpc-simulation:latest container/simulation-task/
```

### **Step 2: Deploy Kubernetes Services**

```sh
# Deploy workloads and meta-scheduler in Kubernetes
kubectl apply -f k8s-deployments/data-processing.yaml
kubectl apply -f k8s-deployments/ml-task.yaml
kubectl apply -f k8s-deployments/simulation-task.yaml
kubectl apply -f k8s-deployments/scheduler-deployment.yaml
```

### **Step 3: Start Monitoring (Optional)**

```sh
# Deploy Prometheus for monitoring
kubectl apply -f monitoring/prometheus-config.yaml
# Forward Prometheus port to access metrics
kubectl port-forward svc/prometheus 9090:9090
```

---

## **Future Work**

âœ”ï¸ **Dynamic Energy-Aware Scheduling**: Improve scheduling decisions with **machine learning models** for energy prediction.\
âœ”ï¸ **Multi-Metric Optimization**: Optimize for **latency, throughput, and power consumption** simultaneously.\
âœ”ï¸ **Support for GPU Workloads**: Extend scheduler capabilities to optimize GPU-based machine learning and simulations.\
âœ”ï¸ **Adaptive Scaling**: Dynamically adjust the number of pods based on **real-time energy availability**.

---

